<!doctype html>
<html lang="zh-cn">
  <head>
    <title> // 小小的梦想</title>
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.62.0" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="del2z" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://del2z.github.io/css/main.min.f90f5edd436ec7b74ad05479a05705770306911f721193e7845948fb07fe1335.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content=""/>
<meta name="twitter:description" content="Transformer到XLNet Transformer Transformer最初是作为机器翻译的模型被提出的，是Encoder-Decoder结构。Transformer的编码器和解码器采用了类似的子结构，之后的文献一般称之为Transformer组块。Transformer模型在编码器和解码器都堆叠了6层组块，网络结构图如下所示。
每个Transformer组块主要包含多头注意力、残差连接、层归一化、位置前馈网络等基本部分，下面分步详解。
Positional Encoding Multi-head Attention Position-wise FFN ELMo GPT/GPT-2 BERT Transformer-XL XLNet RoBERTa "/>

    <meta property="og:title" content="" />
<meta property="og:description" content="Transformer到XLNet Transformer Transformer最初是作为机器翻译的模型被提出的，是Encoder-Decoder结构。Transformer的编码器和解码器采用了类似的子结构，之后的文献一般称之为Transformer组块。Transformer模型在编码器和解码器都堆叠了6层组块，网络结构图如下所示。
每个Transformer组块主要包含多头注意力、残差连接、层归一化、位置前馈网络等基本部分，下面分步详解。
Positional Encoding Multi-head Attention Position-wise FFN ELMo GPT/GPT-2 BERT Transformer-XL XLNet RoBERTa " />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://del2z.github.io/algorithm/transformer-to-xlnet/" />



  </head>
  <body>
    <header class="app-header">
      <a href="https://del2z.github.io/"><img class="app-header-avatar" src="/avatar.jpg" alt="del2z" /></a>
      <h1>小小的梦想</h1>
      <p>del2z的个人站点，记录走过的路、踩过的坑、做过的事、吃过的苦，一路收获，一路成长。</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/del2z" rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title"></h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Jan 1, 0001
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          1 min read
        </div></div>
    </header>
    <div class="post-content">
      <h1 id="transformerxlnet">Transformer到XLNet</h1>
<h2 id="transformer">Transformer</h2>
<p>Transformer最初是作为机器翻译的模型被提出的，是Encoder-Decoder结构。Transformer的编码器和解码器采用了类似的子结构，之后的文献一般称之为Transformer组块。Transformer模型在编码器和解码器都堆叠了6层组块，网络结构图如下所示。</p>
<!-- raw HTML omitted -->
<p>每个Transformer组块主要包含多头注意力、残差连接、层归一化、位置前馈网络等基本部分，下面分步详解。</p>
<h3 id="positional-encoding">Positional Encoding</h3>
<h3 id="multi-head-attention">Multi-head Attention</h3>
<h3 id="position-wise-ffn">Position-wise FFN</h3>
<h2 id="elmo">ELMo</h2>
<h2 id="gptgpt-2">GPT/GPT-2</h2>
<h2 id="bert">BERT</h2>
<h2 id="transformer-xl">Transformer-XL</h2>
<h2 id="xlnet">XLNet</h2>
<h2 id="roberta">RoBERTa</h2>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
