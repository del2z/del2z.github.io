<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Algorithms on 小小的梦想</title>
    <link>https://del2z.github.io/algorithm/</link>
    <description>Recent content in Algorithms on 小小的梦想</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    
	<atom:link href="https://del2z.github.io/algorithm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/bagging-algorithms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/bagging-algorithms/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/boosting-algorithms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/boosting-algorithms/</guid>
      <description>Boosting算法 基本原理 Boosting算法是一种通用的学习框架，通过集成一组基学习器（base learner），更好的拟合目标函数，属于集成学习（Ensemble Learning）算法。基学习器可以是任意回归算法$\mathcal{A}$训练的模型。因此，boosting算法采用集成的方式，可以有效提升这种算法$\mathcal{A}$的泛化能力。
Boosting算法通常采用逐步累加的方式训练模型，用如下的形式表示。 $$ f(\mathbf{x}) \overset{def}{=} F_T(\mathbf{x}) = \sum_{i=0}^T \beta_i, \phi_i (\mathbf{x}) $$ 针对不同的学习任务定义不同的损失函数$\mathcal{L}(f)$，并通过逐步最小化损失函数，训练每一步的基学习器，最终获得Boosting模型。 $$ L(y,, f(\mathbf{x})) = L(F), \quad \forall: (y,, \mathbf{x}) \in \mathcal{D} \[5pt]
\min_f \mathcal{L}(f) ;\Longleftrightarrow; \min_{\beta}\min_{\phi \in \mathcal{F}} \frac{1}{N} \sum_{i=1}^N L(y_i, F_{t-1}(\mathbf{x}_i) + \beta \phi(\mathbf{x}_i)) \[5pt] : \phi_t = \phi^\ast, \quad t = 0, \dots, T $$
直观上看，Boosting算法很难训练，因为每一个基学习器都涉及大量的优化计算。但实际上，通过对损失函数的近似估计，可以大大简化训练过程，特别是采用树模型作基学习器的Boosting算法。 利用Taylor展开式近似计算损失函数可以推导出不同的Boosting算法。通过一阶近似推导的Boosting算法通常称为梯度提升算法（Gradient Boosting algorithm），二阶近似的Boosting算法一般称为Newton提升算法（Newton Boosting algorithm）。
梯度提升算法 一阶Taylor展开式如下。 $$ f(x + \Delta x) \approx f(x) + \frac{d f(x)}{d x} \Delta x, \quad |\Delta x| \approx 0 $$</description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/clustering-algorithms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/clustering-algorithms/</guid>
      <description>聚类算法 K-means DBSCAN </description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/decision-tree/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/decision-tree/</guid>
      <description>决策树 C4.5 CART 误差分析 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/expectation-maximization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/expectation-maximization/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/gradient-descent/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/gradient-descent/</guid>
      <description>Gradient Descent optimization methods 基本原理 SGD Momentum NAG AdaGrad AdaDelta RMSprop Adam Nadam </description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/information-theory/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/information-theory/</guid>
      <description>信息论 基础知识 条件概率 条件概率（Conditional probability）就是指在事件$B$发生的情况下，另一事件$A$发生的概率，用$P(A | B)$表示。
Bayes公式 全概率公式 指标 熵 $$ H(X) = \mathbb{E}_X [ -\log p(x) ] = -\sum_x p(x) \log p(x) $$
联合熵 $$ H(X, Y) = \mathbb{E}{X, Y} [ -\log p(x, y) ] = -\sum{x,, y} p(x, y) \log p(x, y) $$
条件熵 $$ H(X | Y) = \mathbb{E}Y [ H(X | y) ] = -\sum_y p(y) \sum_x p(x | y) \log p(x | y) = -\sum{x,, y} p(x, y) \log p(x | y) \[5pt] H(X | Y) = -\sum_{x,, y} p(x, y) \log \frac{p(x, y)}{p(y)} = -\sum_{x,, y} p(x, y) \log p(x, y) + \sum_y \log p(y) \sum_x p(x, y) = H(X, Y) - H(Y) $$</description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/language-models/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/language-models/</guid>
      <description>语言模型 定义 语言模型是词语序列的概率分布。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/logistic-regression/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/logistic-regression/</guid>
      <description>逻辑回归 </description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/loss-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/loss-functions/</guid>
      <description>损失函数 通用形式 在监督学习中，损失是用于衡量目标值与预测值的期望误差，而这个误差需要通过损失函数来计算，损失的一般形式表示如下。
$$ \mathcal{L}(f) = \mathbb{E}{Y,, X} \big[L \big(Y,, f(X)\big)\big] = \mathbb{E}{X} \big[\mathbb{E}_{Y | X} \big[L\big(Y,, f(X)\big), |, X\big]\big] $$ 根据上述表示，损失的计算涉及标签和特征的概率分布。在大多数情况下，这些概率分布式未知的，特别是特征的条件概率分布。 幸运的是，利用一个已知数据集$\mathcal{D} = {(y_i,, \mathbf{x}i)}{i=1}^N$，可以直接估计损失，而不必考虑标签和特征的概率分布。这是因为，数据集$\mathcal{D}$中的样本是根据标签和样本的联合概率分布$P(Y, X)$采样得到的。
那么，数据集$\mathcal{D}$的损失可以通过如下方式计算。 $$ \mathcal{L}(f) \approx \mathbb{E}\mathcal{D} [L(Y,, f(X))] = \frac{1}{N} \sum{i=1}^N L(y_i,, f(\mathbf{x}_i)) $$
0-1损失 $$ L(y,, f(\mathbf{x})) = \mathbf{1} [y \neq g( f(\mathbf{x}) )], \quad g(z) = \begin{cases} 1, &amp;amp; z \geq 0 \
-1, &amp;amp; z &amp;lt; 0 \end{cases} $$
均方差损失 $$ L(y,, f(\mathbf{x})) = (y - f(\mathbf{x}))^2 $$</description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/reinforcement-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/reinforcement-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/support-vector-machine/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/support-vector-machine/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/transfer-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/transfer-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://del2z.github.io/algorithm/transformer-to-xlnet/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://del2z.github.io/algorithm/transformer-to-xlnet/</guid>
      <description>Transformer到XLNet Transformer Transformer最初是作为机器翻译的模型被提出的，是Encoder-Decoder结构。Transformer的编码器和解码器采用了类似的子结构，之后的文献一般称之为Transformer组块。Transformer模型在编码器和解码器都堆叠了6层组块，网络结构图如下所示。
每个Transformer组块主要包含多头注意力、残差连接、层归一化、位置前馈网络等基本部分，下面分步详解。
Positional Encoding Multi-head Attention Position-wise FFN ELMo GPT/GPT-2 BERT Transformer-XL XLNet RoBERTa </description>
    </item>
    
  </channel>
</rss>